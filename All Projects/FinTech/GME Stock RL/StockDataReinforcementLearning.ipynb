{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e984f863",
   "metadata": {},
   "source": [
    "# Reinforcement Learning visualized on Simple Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4a757",
   "metadata": {},
   "source": [
    "### What is reinforcement learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9110ba4",
   "metadata": {},
   "source": [
    "Reinforment learning is type of machine learning paradigm where an \"agent\" learns to make decisions by interacting with an environment. The agent takes actions in the environment and receives feedback in the form of rewards or penalties, indicating the success or failure of its actions. The goal of the agent is to maximize the total cumulative reward it receives over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078bb3b",
   "metadata": {},
   "source": [
    "The RL process is modeled after the Markov Decision model, which consists of the following components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6d848",
   "metadata": {},
   "source": [
    "- agent: The learner and decision maker that interacts with the enviornment\n",
    "- enviornemnt: The external sytem which the agent interacts with\n",
    "- state: A representation of a particular moment in time. capturing all relevent info for the agent\n",
    "- action: set of decisions for the agent to make given a state\n",
    "- reward: A scalar value that the environment provides as feedback after each action. It represents the immediate positive or negative consequences of the agent's action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b107076",
   "metadata": {},
   "source": [
    "### About the dataset that we will be working with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd86bf6",
   "metadata": {},
   "source": [
    "We will use a finance dataset that describes general information about how the stock behaved over the course of a decade or so. This data is not only insightful but extremely simple to work with. We will focus our attention to the \"open\" and \"close\" column as those values are our best indicators of any relevant information about the specfic stock. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e219e",
   "metadata": {},
   "source": [
    "#### lets read the dataset into our notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76306d0e",
   "metadata": {},
   "source": [
    "1. import the pandas package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810e6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef71230",
   "metadata": {},
   "source": [
    "2. lets read the .csv file into a dataframe using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c52f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  open_price  high_price   low_price  close_price  \\\n",
      "0     2021-01-28  265.000000  483.000000  112.250000   193.600006   \n",
      "1     2021-01-27  354.829987  380.000000  249.000000   347.510010   \n",
      "2     2021-01-26   88.559998  150.000000   80.199997   147.979996   \n",
      "3     2021-01-25   96.730003  159.179993   61.130001    76.790001   \n",
      "4     2021-01-22   42.590000   76.760002   42.320000    65.010002   \n",
      "...          ...         ...         ...         ...          ...   \n",
      "4768  2002-02-20    9.600000    9.875000    9.525000     9.875000   \n",
      "4769  2002-02-19    9.900000    9.900000    9.375000     9.550000   \n",
      "4770  2002-02-15   10.000000   10.025000    9.850000     9.950000   \n",
      "4771  2002-02-14   10.175000   10.195000    9.925000    10.000000   \n",
      "4772  2002-02-13    9.625000   10.060000    9.525000    10.050000   \n",
      "\n",
      "           volume  adjclose_price  \n",
      "0      58815800.0      193.600006  \n",
      "1      93396700.0      347.510010  \n",
      "2     178588000.0      147.979996  \n",
      "3     177874000.0       76.790001  \n",
      "4     196784300.0       65.010002  \n",
      "...           ...             ...  \n",
      "4768    1723200.0        6.648838  \n",
      "4769    1852600.0        6.430017  \n",
      "4770    2097400.0        6.699336  \n",
      "4771    2755400.0        6.733003  \n",
      "4772   19054000.0        6.766666  \n",
      "\n",
      "[4773 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"GME_stock.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177040bc",
   "metadata": {},
   "source": [
    "### How do we apply RL to this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f61a45",
   "metadata": {},
   "source": [
    "To utilize this machine learning paradigm we need to consider formulating a problem using this dataset. What does that mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91413bfd",
   "metadata": {},
   "source": [
    "1. Define the Enviornment \n",
    "2. Implement the agent\n",
    "3. Training\n",
    "4. Evaluation\n",
    "5. Tuning\n",
    "6. Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559b52c",
   "metadata": {},
   "source": [
    "#### Defining the Enviornement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411e71a",
   "metadata": {},
   "source": [
    "- Define the state space: This could be relevant indicators such as moving averages, and other strong indicators \n",
    "- Define the action space: The actions the agent can \"take\", in this context \"buy\", \"sell\", \"hold\" \n",
    "- Define the reward function: The reward function should be designed to reward profitable decisions and penalize unprofitable ones. The reward could be based on the change in portfolio value or other performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8be87",
   "metadata": {},
   "source": [
    "#### Implement the agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76eb79",
   "metadata": {},
   "source": [
    "- Choose a suitable Reinforcement Learning algorithm such as Q-learning, Deep Q Networks (DQNs), Proximal Policy Optimization (PPO), etc.\n",
    "- Define the neural network architecture for the agent if using DQNs or other deep RL methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39f9f6",
   "metadata": {},
   "source": [
    "#### Training: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be413b",
   "metadata": {},
   "source": [
    "- Train the agent on historical financial data. The agent interacts with the environment, observes states, takes actions, and receives rewards during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985917eb",
   "metadata": {},
   "source": [
    "#### Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0fa9d",
   "metadata": {},
   "source": [
    "- Evaluate the trained agent on a separate test dataset to assess its performance in a more realistic scenario.\n",
    "- Consider using metrics like the final portfolio value, annualized return, Sharpe ratio, or other performance measures to evaluate the agent's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0789f8",
   "metadata": {},
   "source": [
    "#### Fine-Tuning and Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e3136",
   "metadata": {},
   "source": [
    "- Depending on the results, you may need to fine-tune hyperparameters, adjust the reward function, or modify the architecture to improve the agent's performance.\n",
    "- Iterativly refines the RL model to improve the agent's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b7d38",
   "metadata": {},
   "source": [
    "#### Implementation Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c165ad8",
   "metadata": {},
   "source": [
    "- Take into account transaction costs and slippage in the environment simulation to make the RL model more realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb1bdd",
   "metadata": {},
   "source": [
    "### Lets try and implement the Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55be2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443253db",
   "metadata": {},
   "source": [
    "Lets set up a class to set our enviornment up for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6472d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enviornment:\n",
    "    #Initialize the Trading Enviornment\n",
    "    #Paramaters: dataframe, window-size for short term, window-size for long term\n",
    "    def __init__(self, data, short_window, long_window):\n",
    "        self.data = data\n",
    "        self.short_window = short_window\n",
    "        self.long_window = long_window\n",
    "        self.current_step = 0\n",
    "        self.current_position = 0\n",
    "        self.initial_balance = 10000.0\n",
    "        self.balance = self.initial_balance\n",
    "        self.stock_owned = 0\n",
    "    \n",
    "    #Resetting the Trading Enviornment\n",
    "    #Paramaters: dataframe\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.current_position = 0\n",
    "        self.balance = self.initial_balance\n",
    "        self.stock_owned = 0\n",
    "        return self._get_observation()\n",
    "    \n",
    "    #Get the current observation representing the state\n",
    "    def _get_observation(self):\n",
    "        start = max(0, self.current_step - self.long_window + 1)\n",
    "        end = self.current_step + 1\n",
    "        prices = self.data.iloc[start:end]['adjclose_price'].values\n",
    "        return np.concatenate([prices])\n",
    "    \n",
    "    #Calculate reward based on the current state and action\n",
    "    def _calculate_reward(self):\n",
    "        return self.balance + self.stock_owned * self.data.iloc[self.current_step]['adjclose_price']\n",
    "    \n",
    "    #Performs a single step in the fEnviornment\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        if action == 0 and self.current_position != 1:  # Buy\n",
    "            self.stock_owned = self.balance / self.data.iloc[self.current_step]['adjclose_price']\n",
    "            self.balance = 0\n",
    "            self.current_position = 1\n",
    "        elif action == 1 and self.current_position != -1:  # Sell\n",
    "            self.balance = self.stock_owned * self.data.iloc[self.current_step]['adjclose_price']\n",
    "            self.stock_owned = 0\n",
    "            self.current_position = -1\n",
    "\n",
    "        done = self.current_step == len(self.data) - 1\n",
    "        reward = self._calculate_reward() - self.initial_balance\n",
    "        return self._get_observation(), reward, done, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73a583",
   "metadata": {},
   "source": [
    "Now that we have this enviornment lets create some simple test data and run some of the functions. What we will want to see is the outcome of perfroming the steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436610e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 1, Reward: -10000.0, Done: False, Current Balance: 0.0, Stock Owned: 0\n",
      "Action: 1, Reward: -10000.0, Done: False, Current Balance: 0.0, Stock Owned: 0\n",
      "Action: 0, Reward: -10000.0, Done: False, Current Balance: 0, Stock Owned: 0.0\n",
      "Action: 0, Reward: -10000.0, Done: False, Current Balance: 0, Stock Owned: 0.0\n",
      "Action: 1, Reward: -10000.0, Done: False, Current Balance: 0.0, Stock Owned: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    data = pd.DataFrame({\n",
    "        'date': ['2021-01-28', '2021-01-27', '2021-01-26', '2021-01-25', '2021-01-22', '2021-01-21', '2021-01-20', '2021-01-19', '2021-01-15', '2021-01-14'],\n",
    "        'adjclose_price': [193.60000610351562, 347.510009765625, 147.97999572753906, 76.79000091552734, 65.01000213623047, 43.029998779296875, 39.119998931884766, 39.36000061035156, 35.5, 39.90999984741211]\n",
    "    })\n",
    "\n",
    "    # Initialize the environment\n",
    "    env = Enviornment(data=data, short_window=2, long_window=5)\n",
    "\n",
    "    # Reset the environment and get the initial observation\n",
    "    observation = env.reset()\n",
    "\n",
    "    # Run some steps in the environment (for illustration purposes)\n",
    "    for _ in range(5):\n",
    "        action = np.random.choice([0, 1])  # Random action (buy or sell)\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        print(f\"Action: {action}, Reward: {reward}, Done: {done}, Current Balance: {env.balance}, Stock Owned: {env.stock_owned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51f44a",
   "metadata": {},
   "source": [
    "Lets try and understand what each line here represents\n",
    "\n",
    "1. Action: 1, Reward: -10000.0, Done: False, Current Balance: 0.0, Stock Owned: 0\n",
    "- the agent took to \"sell\" as action indicates \"1\"\n",
    "- the reward being -10000 means that the agent lost 10000 in its initial balance\n",
    "- the episode is not finished\n",
    "- since he sold he has no stocks\n",
    "\n",
    "The rest of the lines are a the same parameters other than the action being different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c4a2f",
   "metadata": {},
   "source": [
    "### Lets now set up the agent for the RL Enviornment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addde6be",
   "metadata": {},
   "source": [
    "We need to define a agent using an algorithm provided by the RL library that we choose to use. There are several options we can choose from. Here is a list of the current most used algorithms that are used to define RL agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7410c66",
   "metadata": {},
   "source": [
    "1. DQN (Deep Q Network) \n",
    "This algorithm stems from the \"gym\" package in python. It is a popular reinforcement learning algorithm that combines Q-learning. The key idea behind DQN is to use deep neural networks to approximate the Q-function, which represents the expected cumulative future rewards for taking a specifc action in a given state and following a certain policy thereafter\n",
    "\n",
    "2. PPO (Proximal Policy Optimization)\n",
    "Another popular reinforcement learing algorithm that belong to a policy optimization mehtod. PPO operates by iteratively updating the policy to improve its performance while ensuring that the policy updates remains within a certain region to prevent overly large policy changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea42a9",
   "metadata": {},
   "source": [
    "For this dataset we will utilize a very simple Random Agent algorithm to set up our agent. This could also be done using PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee62bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class TradingGymEnv(gym.Env):\n",
    "    def __init__(self, data, short_window, long_window):\n",
    "        self.env = Enviornment(data, short_window, long_window)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(short_window + long_window,))  # Replace with correct shape\n",
    "        self.action_space = gym.spaces.Discrete(2)  # Buy or sell\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "data = pd.read_csv(\"GME_stock.csv\")\n",
    "\n",
    "# Initialize the Gym-compatible environment\n",
    "env = TradingGymEnv(data=data, short_window=2, long_window=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8d86dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Reward: 0.0, Done: False\n",
      "Action: 1, Reward: -5741.705517278687, Done: False\n",
      "Action: 0, Reward: -5741.705517278687, Done: False\n",
      "Action: 1, Reward: -6394.950773305251, Done: False\n",
      "Action: 0, Reward: -6394.950773305251, Done: False\n",
      "Action: 0, Reward: -6722.53019059939, Done: False\n",
      "Action: 0, Reward: -6702.422872683814, Done: False\n",
      "Action: 0, Reward: -7025.813358627411, Done: False\n",
      "Action: 1, Reward: -6656.343988637882, Done: False\n",
      "Action: 1, Reward: -6656.343988637882, Done: False\n",
      "Action: 0, Reward: -6656.343988637882, Done: False\n",
      "Action: 0, Reward: -6658.020044985602, Done: False\n",
      "Action: 1, Reward: -7035.124091995988, Done: False\n",
      "Action: 1, Reward: -7035.124091995988, Done: False\n",
      "Action: 1, Reward: -7035.124091995988, Done: False\n",
      "Action: 0, Reward: -7035.124091995988, Done: False\n",
      "Action: 0, Reward: -7055.606969370396, Done: False\n",
      "Action: 0, Reward: -6784.210716154175, Done: False\n",
      "Action: 0, Reward: -6712.521133690187, Done: False\n",
      "Action: 1, Reward: -6692.038581880071, Done: False\n",
      "Action: 0, Reward: -6692.038581880071, Done: False\n",
      "Action: 1, Reward: -6824.420102903192, Done: False\n",
      "Action: 1, Reward: -6824.420102903192, Done: False\n",
      "Action: 1, Reward: -6824.420102903192, Done: False\n",
      "Action: 0, Reward: -6824.420102903192, Done: False\n",
      "Action: 0, Reward: -6803.9719891519035, Done: False\n",
      "Action: 0, Reward: -6967.556314139216, Done: False\n",
      "Action: 1, Reward: -7167.946970868117, Done: False\n",
      "Action: 0, Reward: -7167.946970868117, Done: False\n",
      "Action: 0, Reward: -7399.009798223952, Done: False\n",
      "Action: 1, Reward: -7278.366356108213, Done: False\n",
      "Action: 0, Reward: -7278.366356108213, Done: False\n",
      "Action: 1, Reward: -7367.031482890028, Done: False\n",
      "Action: 1, Reward: -7367.031482890028, Done: False\n",
      "Action: 0, Reward: -7367.031482890028, Done: False\n",
      "Action: 1, Reward: -7278.460801432664, Done: False\n",
      "Action: 1, Reward: -7278.460801432664, Done: False\n",
      "Action: 1, Reward: -7278.460801432664, Done: False\n",
      "Action: 1, Reward: -7278.460801432664, Done: False\n",
      "Action: 1, Reward: -7278.460801432664, Done: False\n",
      "Action: 1, Reward: -7278.460801432664, Done: False\n",
      "Action: 0, Reward: -7278.460801432664, Done: False\n",
      "Action: 1, Reward: -7477.732810030344, Done: False\n",
      "Action: 0, Reward: -7477.732810030344, Done: False\n",
      "Action: 0, Reward: -7693.6678445663965, Done: False\n",
      "Action: 0, Reward: -7739.032363616583, Done: False\n",
      "Action: 1, Reward: -7900.5301137339375, Done: False\n",
      "Action: 1, Reward: -7900.5301137339375, Done: False\n",
      "Action: 0, Reward: -7900.5301137339375, Done: False\n",
      "Action: 0, Reward: -8083.319807292797, Done: False\n",
      "Action: 0, Reward: -8062.429580317608, Done: False\n",
      "Action: 0, Reward: -7954.496657935417, Done: False\n",
      "Action: 1, Reward: -8067.652095556214, Done: False\n",
      "Action: 1, Reward: -8067.652095556214, Done: False\n",
      "Action: 0, Reward: -8067.652095556214, Done: False\n",
      "Action: 0, Reward: -8134.453307099506, Done: False\n",
      "Action: 1, Reward: -8222.435417124183, Done: False\n",
      "Action: 0, Reward: -8222.435417124183, Done: False\n",
      "Action: 0, Reward: -8348.416614525646, Done: False\n",
      "Action: 0, Reward: -8391.434559354713, Done: False\n",
      "Action: 1, Reward: -8197.853734364717, Done: False\n",
      "Action: 0, Reward: -8197.853734364717, Done: False\n",
      "Action: 1, Reward: -8065.208464877107, Done: False\n",
      "Action: 1, Reward: -8065.208464877107, Done: False\n",
      "Action: 1, Reward: -8065.208464877107, Done: False\n",
      "Action: 0, Reward: -8065.208464877107, Done: False\n",
      "Action: 1, Reward: -8170.317795943358, Done: False\n",
      "Action: 0, Reward: -8170.317795943358, Done: False\n",
      "Action: 1, Reward: -8163.717185448902, Done: False\n",
      "Action: 1, Reward: -8163.717185448902, Done: False\n",
      "Action: 0, Reward: -8163.717185448902, Done: False\n",
      "Action: 1, Reward: -8373.502197950624, Done: False\n",
      "Action: 0, Reward: -8373.502197950624, Done: False\n",
      "Action: 1, Reward: -8384.455034551513, Done: False\n",
      "Action: 0, Reward: -8384.455034551513, Done: False\n",
      "Action: 1, Reward: -8186.880167707919, Done: False\n",
      "Action: 0, Reward: -8186.880167707919, Done: False\n",
      "Action: 0, Reward: -8231.433238941132, Done: False\n",
      "Action: 0, Reward: -8167.50915472394, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 1, Reward: -8181.068752971323, Done: False\n",
      "Action: 0, Reward: -8181.068752971323, Done: False\n",
      "Action: 0, Reward: -8031.3966405635865, Done: False\n",
      "Action: 0, Reward: -8087.523757059403, Done: False\n",
      "Action: 0, Reward: -8195.620139508264, Done: False\n",
      "Action: 0, Reward: -8526.14596354512, Done: False\n",
      "Action: 0, Reward: -8563.564041208996, Done: False\n",
      "Action: 0, Reward: -8734.023820348397, Done: False\n",
      "Action: 0, Reward: -8704.920948150626, Done: False\n",
      "Action: 1, Reward: -8472.097772320689, Done: False\n",
      "Action: 1, Reward: -8472.097772320689, Done: False\n",
      "Action: 1, Reward: -8472.097772320689, Done: False\n",
      "Action: 1, Reward: -8472.097772320689, Done: False\n",
      "Action: 0, Reward: -8472.097772320689, Done: False\n",
      "Action: 1, Reward: -8483.98805063196, Done: False\n",
      "Action: 1, Reward: -8483.98805063196, Done: False\n",
      "Action: 0, Reward: -8483.98805063196, Done: False\n",
      "Action: 1, Reward: -8523.364947804406, Done: False\n",
      "Action: 1, Reward: -8523.364947804406, Done: False\n",
      "Action: 1, Reward: -8523.364947804406, Done: False\n",
      "Action: 0, Reward: -8523.364947804406, Done: False\n",
      "Action: 1, Reward: -8474.85117106907, Done: False\n",
      "Action: 0, Reward: -8474.85117106907, Done: False\n",
      "Action: 0, Reward: -8438.459448139505, Done: False\n",
      "Action: 1, Reward: -8408.684258693169, Done: False\n",
      "Action: 1, Reward: -8408.684258693169, Done: False\n",
      "Action: 1, Reward: -8408.684258693169, Done: False\n",
      "Action: 1, Reward: -8408.684258693169, Done: False\n",
      "Action: 0, Reward: -8408.684258693169, Done: False\n",
      "Action: 1, Reward: -8468.534656607211, Done: False\n",
      "Action: 1, Reward: -8468.534656607211, Done: False\n",
      "Action: 1, Reward: -8468.534656607211, Done: False\n",
      "Action: 0, Reward: -8468.534656607211, Done: False\n",
      "Action: 0, Reward: -8399.393907464299, Done: False\n",
      "Action: 1, Reward: -8468.534656607211, Done: False\n",
      "Action: 1, Reward: -8468.534656607211, Done: False\n",
      "Action: 0, Reward: -8468.534656607211, Done: False\n",
      "Action: 1, Reward: -8434.162742277604, Done: False\n",
      "Action: 0, Reward: -8434.162742277604, Done: False\n",
      "Action: 0, Reward: -8480.4436029621, Done: False\n",
      "Action: 1, Reward: -8453.44634227758, Done: False\n",
      "Action: 1, Reward: -8453.44634227758, Done: False\n",
      "Action: 0, Reward: -8453.44634227758, Done: False\n",
      "Action: 1, Reward: -8453.44634227758, Done: False\n",
      "Action: 1, Reward: -8453.44634227758, Done: False\n",
      "Action: 1, Reward: -8453.44634227758, Done: False\n",
      "Action: 1, Reward: -8453.44634227758, Done: False\n",
      "Action: 0, Reward: -8453.44634227758, Done: False\n",
      "Action: 0, Reward: -8446.028825948955, Done: False\n",
      "Action: 1, Reward: -8486.825254180163, Done: False\n",
      "Action: 0, Reward: -8486.825254180163, Done: False\n",
      "Action: 1, Reward: -8458.408855655392, Done: False\n",
      "Action: 1, Reward: -8458.408855655392, Done: False\n",
      "Action: 0, Reward: -8458.408855655392, Done: False\n",
      "Action: 0, Reward: -8519.927775390624, Done: False\n",
      "Action: 1, Reward: -8465.646538029745, Done: False\n",
      "Action: 0, Reward: -8465.646538029745, Done: False\n",
      "Action: 0, Reward: -8411.997780997246, Done: False\n",
      "Action: 1, Reward: -8447.76356217068, Done: False\n",
      "Action: 1, Reward: -8447.76356217068, Done: False\n",
      "Action: 0, Reward: -8447.76356217068, Done: False\n",
      "Action: 1, Reward: -8408.511557768263, Done: False\n",
      "Action: 1, Reward: -8408.511557768263, Done: False\n",
      "Action: 0, Reward: -8408.511557768263, Done: False\n",
      "Action: 0, Reward: -8395.331541622434, Done: False\n",
      "Action: 1, Reward: -8392.036459026884, Done: False\n",
      "Action: 0, Reward: -8392.036459026884, Done: False\n",
      "Action: 0, Reward: -8453.756137780141, Done: False\n",
      "Action: 1, Reward: -8492.737191329992, Done: False\n",
      "Action: 0, Reward: -8492.737191329992, Done: False\n",
      "Action: 1, Reward: -8483.095937337279, Done: False\n",
      "Action: 0, Reward: -8483.095937337279, Done: False\n",
      "Action: 1, Reward: -8240.113487529321, Done: False\n",
      "Action: 1, Reward: -8240.113487529321, Done: False\n",
      "Action: 0, Reward: -8240.113487529321, Done: False\n",
      "Action: 0, Reward: -8545.722635967917, Done: False\n",
      "Action: 0, Reward: -8429.801999577794, Done: False\n",
      "Action: 1, Reward: -8440.340147885525, Done: False\n",
      "Action: 0, Reward: -8440.340147885525, Done: False\n",
      "Action: 0, Reward: -8458.996260226671, Done: False\n",
      "Action: 0, Reward: -8485.115031007761, Done: False\n",
      "Action: 0, Reward: -8384.371455022943, Done: False\n",
      "Action: 0, Reward: -8250.046627736663, Done: False\n",
      "Action: 0, Reward: -8350.79020372148, Done: False\n",
      "Action: 0, Reward: -8440.340147885525, Done: False\n",
      "Action: 0, Reward: -8343.32772320111, Done: False\n",
      "Action: 0, Reward: -8347.05905242108, Done: False\n",
      "Action: 1, Reward: -8343.32772320111, Done: False\n",
      "Action: 0, Reward: -8343.32772320111, Done: False\n",
      "Action: 0, Reward: -8473.546555247423, Done: False\n",
      "Action: 0, Reward: -8506.101133898263, Done: False\n",
      "Action: 1, Reward: -8477.163653994856, Done: False\n",
      "Action: 0, Reward: -8477.163653994856, Done: False\n",
      "Action: 1, Reward: -8403.369732061527, Done: False\n",
      "Action: 0, Reward: -8403.369732061527, Done: False\n",
      "Action: 0, Reward: -8438.636708361468, Done: False\n",
      "Action: 0, Reward: -8419.400217528237, Done: False\n",
      "Action: 0, Reward: -8271.920301595435, Done: False\n",
      "Action: 1, Reward: -8243.06548890657, Done: False\n",
      "Action: 0, Reward: -8243.06548890657, Done: False\n",
      "Action: 0, Reward: -8335.994303356641, Done: False\n",
      "Action: 1, Reward: -8245.969579268127, Done: False\n",
      "Action: 0, Reward: -8245.969579268127, Done: False\n",
      "Action: 0, Reward: -8189.989788755104, Done: False\n",
      "Action: 0, Reward: -8516.538072429239, Done: False\n",
      "Action: 0, Reward: -8538.308007439364, Done: False\n",
      "Action: 1, Reward: -8479.218310950924, Done: False\n",
      "Action: 1, Reward: -8479.218310950924, Done: False\n",
      "Action: 1, Reward: -8479.218310950924, Done: False\n",
      "Action: 1, Reward: -8479.218310950924, Done: False\n",
      "Action: 0, Reward: -8479.218310950924, Done: False\n",
      "Action: 1, Reward: -8406.656234993003, Done: False\n",
      "Action: 1, Reward: -8406.656234993003, Done: False\n",
      "Action: 1, Reward: -8406.656234993003, Done: False\n",
      "Action: 1, Reward: -8406.656234993003, Done: False\n",
      "Action: 1, Reward: -8406.656234993003, Done: False\n",
      "Action: 0, Reward: -8406.656234993003, Done: False\n",
      "Action: 1, Reward: -8494.363264271691, Done: False\n",
      "Action: 1, Reward: -8494.363264271691, Done: False\n",
      "Action: 0, Reward: -8494.363264271691, Done: False\n",
      "Action: 0, Reward: -8283.04577022508, Done: False\n",
      "Action: 1, Reward: -8150.972367934702, Done: False\n",
      "Action: 1, Reward: -8150.972367934702, Done: False\n",
      "Action: 1, Reward: -8150.972367934702, Done: False\n",
      "Action: 0, Reward: -8150.972367934702, Done: False\n",
      "Action: 1, Reward: -8251.599629576727, Done: False\n",
      "Action: 0, Reward: -8251.599629576727, Done: False\n",
      "Action: 1, Reward: -8398.7005875944, Done: False\n",
      "Action: 1, Reward: -8398.7005875944, Done: False\n",
      "Action: 1, Reward: -8398.7005875944, Done: False\n",
      "Action: 1, Reward: -8398.7005875944, Done: False\n",
      "Action: 0, Reward: -8398.7005875944, Done: False\n",
      "Action: 0, Reward: -8345.702549076814, Done: False\n",
      "Action: 0, Reward: -8262.41973661019, Done: False\n",
      "Action: 1, Reward: -8493.340032345297, Done: False\n",
      "Action: 0, Reward: -8493.340032345297, Done: False\n",
      "Action: 1, Reward: -8460.586498200355, Done: False\n",
      "Action: 0, Reward: -8460.586498200355, Done: False\n",
      "Action: 0, Reward: -8369.053792774876, Done: False\n",
      "Action: 1, Reward: -8352.411500733131, Done: False\n",
      "Action: 1, Reward: -8352.411500733131, Done: False\n",
      "Action: 1, Reward: -8352.411500733131, Done: False\n",
      "Action: 1, Reward: -8352.411500733131, Done: False\n",
      "Action: 1, Reward: -8352.411500733131, Done: False\n",
      "Action: 0, Reward: -8352.411500733131, Done: False\n",
      "Action: 0, Reward: -8390.396213457503, Done: False\n",
      "Action: 0, Reward: -8309.678698918211, Done: False\n",
      "Action: 1, Reward: -8243.205338447187, Done: False\n",
      "Action: 0, Reward: -8243.205338447187, Done: False\n",
      "Action: 1, Reward: -8199.720363132063, Done: False\n",
      "Action: 1, Reward: -8199.720363132063, Done: False\n",
      "Action: 0, Reward: -8199.720363132063, Done: False\n",
      "Action: 0, Reward: -8217.457091657778, Done: False\n",
      "Action: 1, Reward: -8177.549346755677, Done: False\n",
      "Action: 1, Reward: -8177.549346755677, Done: False\n",
      "Action: 1, Reward: -8177.549346755677, Done: False\n",
      "Action: 1, Reward: -8177.549346755677, Done: False\n",
      "Action: 0, Reward: -8177.549346755677, Done: False\n",
      "Action: 0, Reward: -8019.699324298741, Done: False\n",
      "Action: 0, Reward: -8000.566002066821, Done: False\n",
      "Action: 0, Reward: -8053.182524161004, Done: False\n",
      "Action: 1, Reward: -8110.582604900361, Done: False\n",
      "Action: 0, Reward: -8110.582604900361, Done: False\n",
      "Action: 1, Reward: -8066.299308634202, Done: False\n",
      "Action: 1, Reward: -8066.299308634202, Done: False\n",
      "Action: 1, Reward: -8066.299308634202, Done: False\n",
      "Action: 0, Reward: -8066.299308634202, Done: False\n",
      "Action: 0, Reward: -8048.227357676689, Done: False\n",
      "Action: 1, Reward: -7912.687725495336, Done: False\n",
      "Action: 1, Reward: -7912.687725495336, Done: False\n",
      "Action: 0, Reward: -7912.687725495336, Done: False\n",
      "Action: 0, Reward: -7839.927456580341, Done: False\n",
      "Action: 0, Reward: -7899.0452834951275, Done: False\n",
      "Action: 1, Reward: -7903.592691880962, Done: False\n",
      "Action: 0, Reward: -7903.592691880962, Done: False\n",
      "Action: 0, Reward: -7583.12288088797, Done: False\n",
      "Action: 0, Reward: -7583.12288088797, Done: False\n",
      "Action: 0, Reward: -7529.711068856777, Done: False\n",
      "Action: 0, Reward: -7454.044741937016, Done: False\n",
      "Action: 0, Reward: -7543.064074924283, Done: False\n",
      "Action: 1, Reward: -7396.182069375876, Done: False\n",
      "Action: 1, Reward: -7396.182069375876, Done: False\n",
      "Action: 0, Reward: -7396.182069375876, Done: False\n",
      "Action: 0, Reward: -7491.091448003166, Done: False\n",
      "Action: 1, Reward: -7470.458897392917, Done: False\n",
      "Action: 1, Reward: -7470.458897392917, Done: False\n",
      "Action: 0, Reward: -7470.458897392917, Done: False\n",
      "Action: 0, Reward: -7451.721574092358, Done: False\n",
      "Action: 1, Reward: -7372.087838381727, Done: False\n",
      "Action: 1, Reward: -7372.087838381727, Done: False\n",
      "Action: 0, Reward: -7372.087838381727, Done: False\n",
      "Action: 0, Reward: -7328.722992172825, Done: False\n",
      "Action: 1, Reward: -7372.087838381727, Done: False\n",
      "Action: 0, Reward: -7372.087838381727, Done: False\n",
      "Action: 1, Reward: -7395.9780400754335, Done: False\n",
      "Action: 1, Reward: -7395.9780400754335, Done: False\n",
      "Action: 1, Reward: -7395.9780400754335, Done: False\n",
      "Action: 0, Reward: -7395.9780400754335, Done: False\n",
      "Action: 0, Reward: -7467.978766802192, Done: False\n",
      "Action: 0, Reward: -7327.977629230611, Done: False\n",
      "Action: 0, Reward: -7439.978462993289, Done: False\n",
      "Action: 1, Reward: -7427.978469029806, Done: False\n",
      "Action: 0, Reward: -7427.978469029806, Done: False\n",
      "Action: 0, Reward: -7406.965140675644, Done: False\n",
      "Action: 1, Reward: -7335.5200647490365, Done: False\n",
      "Action: 1, Reward: -7335.5200647490365, Done: False\n",
      "Action: 1, Reward: -7335.5200647490365, Done: False\n",
      "Action: 1, Reward: -7335.5200647490365, Done: False\n",
      "Action: 1, Reward: -7335.5200647490365, Done: False\n",
      "Action: 0, Reward: -7335.5200647490365, Done: False\n",
      "Action: 0, Reward: -7354.898082161435, Done: False\n",
      "Action: 0, Reward: -7335.5200647490365, Done: False\n",
      "Action: 0, Reward: -7277.386012511839, Done: False\n",
      "Action: 1, Reward: -7151.428668327055, Done: False\n",
      "Action: 1, Reward: -7151.428668327055, Done: False\n",
      "Action: 0, Reward: -7151.428668327055, Done: False\n",
      "Action: 1, Reward: -7161.019808352722, Done: False\n",
      "Action: 1, Reward: -7161.019808352722, Done: False\n",
      "Action: 0, Reward: -7161.019808352722, Done: False\n",
      "Action: 1, Reward: -7100.417774390282, Done: False\n",
      "Action: 1, Reward: -7100.417774390282, Done: False\n",
      "Action: 1, Reward: -7100.417774390282, Done: False\n",
      "Action: 0, Reward: -7100.417774390282, Done: False\n",
      "Action: 1, Reward: -7105.374202383775, Done: False\n",
      "Action: 0, Reward: -7105.374202383775, Done: False\n",
      "Action: 0, Reward: -6951.06512847608, Done: False\n",
      "Action: 0, Reward: -6908.497143084331, Done: False\n",
      "Action: 0, Reward: -6706.298958748314, Done: False\n",
      "Action: 0, Reward: -6621.162987964816, Done: False\n",
      "Action: 0, Reward: -6583.915873884433, Done: False\n",
      "Action: 0, Reward: -6578.595002573067, Done: False\n",
      "Action: 1, Reward: -6599.878995268941, Done: False\n",
      "Action: 0, Reward: -6599.878995268941, Done: False\n",
      "Action: 0, Reward: -6594.145101633607, Done: False\n",
      "Action: 0, Reward: -6542.541152543979, Done: False\n",
      "Action: 1, Reward: -6628.547643224326, Done: False\n",
      "Action: 0, Reward: -6628.547643224326, Done: False\n",
      "Action: 1, Reward: -6646.5769258722685, Done: False\n",
      "Action: 1, Reward: -6646.5769258722685, Done: False\n",
      "Action: 1, Reward: -6646.5769258722685, Done: False\n",
      "Action: 0, Reward: -6646.5769258722685, Done: False\n",
      "Action: 0, Reward: -6485.289870520478, Done: False\n",
      "Action: 0, Reward: -6310.562574374984, Done: False\n",
      "Action: 1, Reward: -6270.240570200844, Done: False\n",
      "Action: 0, Reward: -6270.240570200844, Done: False\n",
      "Action: 0, Reward: -6339.055253232614, Done: False\n",
      "Action: 1, Reward: -6160.137077350011, Done: False\n",
      "Action: 1, Reward: -6160.137077350011, Done: False\n",
      "Action: 0, Reward: -6160.137077350011, Done: False\n",
      "Action: 1, Reward: -6203.281562192138, Done: False\n",
      "Action: 0, Reward: -6203.281562192138, Done: False\n",
      "Action: 1, Reward: -6342.007511514621, Done: False\n",
      "Action: 0, Reward: -6342.007511514621, Done: False\n",
      "Action: 1, Reward: -6575.186441534319, Done: False\n",
      "Action: 0, Reward: -6575.186441534319, Done: False\n",
      "Action: 0, Reward: -6451.769856014616, Done: False\n",
      "Action: 0, Reward: -6660.035527984333, Done: False\n",
      "Action: 0, Reward: -6644.60845479437, Done: False\n",
      "Action: 0, Reward: -6598.327235224482, Done: False\n",
      "Action: 0, Reward: -6467.196929204579, Done: False\n",
      "Action: 1, Reward: -6459.483208704379, Done: False\n",
      "Action: 0, Reward: -6459.483208704379, Done: False\n",
      "Action: 0, Reward: -6689.02549475196, Done: False\n",
      "Action: 0, Reward: -7002.037974373, Done: False\n",
      "Action: 0, Reward: -7057.684548968808, Done: False\n",
      "Action: 1, Reward: -7231.580260420581, Done: False\n",
      "Action: 0, Reward: -7231.580260420581, Done: False\n",
      "Action: 1, Reward: -7115.321099633053, Done: False\n",
      "Action: 0, Reward: -7115.321099633053, Done: False\n",
      "Action: 0, Reward: -7354.006048917086, Done: False\n",
      "Action: 1, Reward: -7476.758387521773, Done: False\n",
      "Action: 0, Reward: -7476.758387521773, Done: False\n",
      "Action: 1, Reward: -7589.049139495044, Done: False\n",
      "Action: 0, Reward: -7589.049139495044, Done: False\n",
      "Action: 1, Reward: -7794.634055141816, Done: False\n",
      "Action: 1, Reward: -7794.634055141816, Done: False\n",
      "Action: 1, Reward: -7794.634055141816, Done: False\n",
      "Action: 0, Reward: -7794.634055141816, Done: False\n",
      "Action: 0, Reward: -7867.703340521396, Done: False\n",
      "Action: 0, Reward: -7794.634055141816, Done: False\n",
      "Action: 0, Reward: -7694.993962159735, Done: False\n",
      "Action: 0, Reward: -7668.423312930797, Done: False\n",
      "Action: 1, Reward: -7615.28201447292, Done: False\n",
      "Action: 0, Reward: -7615.28201447292, Done: False\n",
      "Action: 1, Reward: -7664.325155943066, Done: False\n",
      "Action: 1, Reward: -7664.325155943066, Done: False\n",
      "Action: 0, Reward: -7664.325155943066, Done: False\n",
      "Action: 1, Reward: -7620.25586174367, Done: False\n",
      "Action: 1, Reward: -7620.25586174367, Done: False\n",
      "Action: 1, Reward: -7620.25586174367, Done: False\n",
      "Action: 0, Reward: -7620.25586174367, Done: False\n",
      "Action: 1, Reward: -7567.110405251756, Done: False\n",
      "Action: 0, Reward: -7567.110405251756, Done: False\n",
      "Action: 1, Reward: -7585.311700542791, Done: False\n",
      "Action: 1, Reward: -7585.311700542791, Done: False\n",
      "Action: 0, Reward: -7585.311700542791, Done: False\n",
      "Action: 1, Reward: -7555.79245369176, Done: False\n",
      "Action: 1, Reward: -7555.79245369176, Done: False\n",
      "Action: 1, Reward: -7555.79245369176, Done: False\n",
      "Action: 0, Reward: -7555.79245369176, Done: False\n",
      "Action: 0, Reward: -7416.282894191427, Done: False\n",
      "Action: 0, Reward: -7349.318369493676, Done: False\n",
      "Action: 1, Reward: -7260.032336563339, Done: False\n",
      "Action: 1, Reward: -7260.032336563339, Done: False\n",
      "Action: 0, Reward: -7260.032336563339, Done: False\n",
      "Action: 0, Reward: -7191.268606521784, Done: False\n",
      "Action: 0, Reward: -7117.215494597453, Done: False\n",
      "Action: 0, Reward: -7080.188812523467, Done: False\n",
      "Action: 1, Reward: -7191.268606521784, Done: False\n",
      "Action: 1, Reward: -7191.268606521784, Done: False\n",
      "Action: 1, Reward: -7191.268606521784, Done: False\n",
      "Action: 0, Reward: -7191.268606521784, Done: False\n",
      "Action: 1, Reward: -7155.324970829746, Done: False\n",
      "Action: 1, Reward: -7155.324970829746, Done: False\n",
      "Action: 1, Reward: -7155.324970829746, Done: False\n",
      "Action: 0, Reward: -7155.324970829746, Done: False\n",
      "Action: 1, Reward: -7128.838137111237, Done: False\n",
      "Action: 0, Reward: -7128.838137111237, Done: False\n",
      "Action: 0, Reward: -7076.918444239563, Done: False\n",
      "Action: 0, Reward: -7024.998751367888, Done: False\n",
      "Action: 0, Reward: -7040.574783015702, Done: False\n",
      "Action: 1, Reward: -7076.918444239563, Done: False\n",
      "Action: 0, Reward: -7076.9184442395635, Done: False\n",
      "Action: 1, Reward: -7179.482614973087, Done: False\n",
      "Action: 1, Reward: -7179.482614973087, Done: False\n",
      "Action: 1, Reward: -7179.482614973087, Done: False\n",
      "Action: 1, Reward: -7179.482614973087, Done: False\n",
      "Action: 0, Reward: -7179.482614973087, Done: False\n",
      "Action: 1, Reward: -7228.965458904151, Done: False\n",
      "Action: 1, Reward: -7228.965458904151, Done: False\n",
      "Action: 0, Reward: -7228.965458904151, Done: False\n",
      "Action: 1, Reward: -7188.1603480534395, Done: False\n",
      "Action: 1, Reward: -7188.1603480534395, Done: False\n",
      "Action: 0, Reward: -7188.1603480534395, Done: False\n",
      "Action: 1, Reward: -7125.014825764406, Done: False\n",
      "Action: 1, Reward: -7125.014825764406, Done: False\n",
      "Action: 0, Reward: -7125.014825764406, Done: False\n",
      "Action: 0, Reward: -7050.339777500755, Done: False\n",
      "Action: 0, Reward: -6964.463587722865, Done: False\n",
      "Action: 1, Reward: -6990.599703282048, Done: False\n",
      "Action: 1, Reward: -6990.599703282048, Done: False\n",
      "Action: 0, Reward: -6990.599703282048, Done: False\n",
      "Action: 1, Reward: -6983.6577755991075, Done: False\n",
      "Action: 0, Reward: -6983.6577755991075, Done: False\n",
      "Action: 0, Reward: -7079.1338518296925, Done: False\n",
      "Action: 0, Reward: -7001.338630377884, Done: False\n",
      "Action: 1, Reward: -6987.193676767459, Done: False\n",
      "Action: 0, Reward: -6987.193676767459, Done: False\n",
      "Action: 0, Reward: -6959.457524768117, Done: False\n",
      "Action: 1, Reward: -6931.721703405845, Done: False\n",
      "Action: 0, Reward: -6931.721703405845, Done: False\n",
      "Action: 0, Reward: -7000.133638280231, Done: False\n",
      "Action: 1, Reward: -7089.06931672385, Done: False\n",
      "Action: 0, Reward: -7089.06931672385, Done: False\n",
      "Action: 0, Reward: -7052.051494068052, Done: False\n",
      "Action: 1, Reward: -7008.3033624329, Done: False\n",
      "Action: 0, Reward: -7008.3033624329, Done: False\n",
      "Action: 0, Reward: -6988.247154897111, Done: False\n",
      "Action: 1, Reward: -7028.359251186084, Done: False\n",
      "Action: 1, Reward: -7028.359251186084, Done: False\n",
      "Action: 0, Reward: -7028.359251186085, Done: False\n",
      "Action: 1, Reward: -6970.756481098211, Done: False\n",
      "Action: 0, Reward: -6970.756481098211, Done: False\n",
      "Action: 1, Reward: -7017.462993897541, Done: False\n",
      "Action: 0, Reward: -7017.46299389754, Done: False\n",
      "Action: 0, Reward: -6876.656350281397, Done: False\n",
      "Action: 1, Reward: -6809.453248825921, Done: False\n",
      "Action: 0, Reward: -6809.453248825921, Done: False\n",
      "Action: 1, Reward: -6770.464933458296, Done: False\n",
      "Action: 1, Reward: -6770.464933458296, Done: False\n",
      "Action: 0, Reward: -6770.464933458296, Done: False\n",
      "Action: 1, Reward: -6899.259831667546, Done: False\n",
      "Action: 0, Reward: -6899.259831667546, Done: False\n",
      "Action: 0, Reward: -6816.3689132379095, Done: False\n",
      "Action: 1, Reward: -6880.839757697315, Done: False\n",
      "Action: 0, Reward: -6880.839757697315, Done: False\n",
      "Action: 0, Reward: -6850.229627477493, Done: False\n",
      "Action: 0, Reward: -6831.86349096163, Done: False\n",
      "Action: 1, Reward: -6896.14453088739, Done: False\n",
      "Action: 1, Reward: -6896.14453088739, Done: False\n",
      "Action: 1, Reward: -6896.14453088739, Done: False\n",
      "Action: 1, Reward: -6896.14453088739, Done: False\n",
      "Action: 0, Reward: -6896.14453088739, Done: False\n",
      "Action: 1, Reward: -6864.992794136491, Done: False\n",
      "Action: 0, Reward: -6864.992794136491, Done: False\n",
      "Action: 1, Reward: -6896.1729652954255, Done: False\n",
      "Action: 1, Reward: -6896.1729652954255, Done: False\n",
      "Action: 1, Reward: -6896.1729652954255, Done: False\n",
      "Action: 1, Reward: -6896.1729652954255, Done: False\n",
      "Action: 0, Reward: -6896.1729652954255, Done: False\n",
      "Action: 0, Reward: -6720.751684249366, Done: False\n",
      "Action: 1, Reward: -6729.239815251359, Done: False\n",
      "Action: 1, Reward: -6729.239815251359, Done: False\n",
      "Action: 1, Reward: -6729.239815251359, Done: False\n",
      "Action: 1, Reward: -6729.239815251359, Done: False\n",
      "Action: 0, Reward: -6729.239815251358, Done: False\n",
      "Action: 0, Reward: -6737.626379120849, Done: False\n",
      "Action: 1, Reward: -6746.012942990341, Done: False\n",
      "Action: 0, Reward: -6746.012942990341, Done: False\n",
      "Action: 0, Reward: -6796.724425263816, Done: False\n",
      "Action: 1, Reward: -6892.512873267609, Done: False\n",
      "Action: 0, Reward: -6892.512873267609, Done: False\n",
      "Action: 0, Reward: -6892.512873267609, Done: False\n",
      "Action: 1, Reward: -6828.698224973539, Done: False\n",
      "Action: 0, Reward: -6828.698224973538, Done: False\n",
      "Action: 0, Reward: -6789.51161355142, Done: False\n",
      "Action: 1, Reward: -6767.119461305316, Done: False\n",
      "Action: 0, Reward: -6767.119461305316, Done: False\n",
      "Action: 1, Reward: -6752.814492926666, Done: False\n",
      "Action: 1, Reward: -6752.814492926666, Done: False\n",
      "Action: 0, Reward: -6752.814492926666, Done: False\n",
      "Action: 1, Reward: -6673.821471413748, Done: False\n",
      "Action: 1, Reward: -6673.821471413748, Done: False\n",
      "Action: 0, Reward: -6673.821471413748, Done: False\n",
      "Action: 1, Reward: -6644.229040217615, Done: False\n",
      "Action: 0, Reward: -6644.229040217615, Done: False\n",
      "Action: 0, Reward: -6620.259051393135, Done: False\n",
      "Action: 1, Reward: -5355.852333479731, Done: False\n",
      "Action: 1, Reward: -5355.852333479731, Done: False\n",
      "Action: 0, Reward: -5355.852333479731, Done: False\n",
      "Action: 1, Reward: -5449.91120383171, Done: False\n",
      "Action: 0, Reward: -5449.91120383171, Done: False\n",
      "Action: 1, Reward: -5253.247273403582, Done: False\n",
      "Action: 1, Reward: -5253.247273403582, Done: False\n",
      "Action: 0, Reward: -5253.247273403582, Done: False\n",
      "Action: 0, Reward: -5298.656553684891, Done: False\n",
      "Action: 1, Reward: -5265.356434711786, Done: False\n",
      "Action: 1, Reward: -5265.356434711786, Done: False\n",
      "Action: 1, Reward: -5265.356434711786, Done: False\n",
      "Action: 0, Reward: -5265.356434711786, Done: False\n",
      "Action: 1, Reward: -5315.724591677625, Done: False\n",
      "Action: 0, Reward: -5315.724591677625, Done: False\n",
      "Action: 1, Reward: -5388.349011986889, Done: False\n",
      "Action: 0, Reward: -5388.349011986889, Done: False\n",
      "Action: 1, Reward: -5352.792957972428, Done: False\n",
      "Action: 0, Reward: -5352.792957972428, Done: False\n",
      "Action: 0, Reward: -5477.995163948466, Done: False\n",
      "Action: 1, Reward: -5514.819064513885, Done: False\n",
      "Action: 0, Reward: -5514.819064513885, Done: False\n",
      "Action: 0, Reward: -5778.865761914407, Done: False\n",
      "Action: 0, Reward: -5673.970522991973, Done: False\n",
      "Action: 0, Reward: -5503.967463947243, Done: False\n",
      "Action: 0, Reward: -5449.711244391586, Done: False\n",
      "Action: 0, Reward: -5395.45538149144, Done: False\n",
      "Action: 0, Reward: -5424.391913035954, Done: False\n",
      "Action: 0, Reward: -5384.603780924797, Done: False\n",
      "Action: 1, Reward: -5373.752537013666, Done: False\n",
      "Action: 1, Reward: -5373.752537013666, Done: False\n",
      "Action: 0, Reward: -5373.752537013666, Done: False\n",
      "Action: 0, Reward: -5273.725452502128, Done: False\n",
      "Action: 0, Reward: -5248.718593311998, Done: False\n",
      "Action: 1, Reward: -5290.396691962213, Done: False\n",
      "Action: 0, Reward: -5290.396691962213, Done: False\n",
      "Action: 1, Reward: -5161.3187914751215, Done: False\n",
      "Action: 0, Reward: -5161.3187914751215, Done: False\n",
      "Action: 0, Reward: -4817.722664341774, Done: False\n",
      "Action: 0, Reward: -4683.117792279622, Done: False\n",
      "Action: 1, Reward: -4785.842477977459, Done: False\n",
      "Action: 0, Reward: -4785.842477977459, Done: False\n",
      "Action: 1, Reward: -5172.076328197263, Done: False\n",
      "Action: 0, Reward: -5172.076328197263, Done: False\n",
      "Action: 0, Reward: -5675.645164860174, Done: False\n",
      "Action: 1, Reward: -5411.535395378268, Done: False\n",
      "Action: 1, Reward: -5411.535395378268, Done: False\n",
      "Action: 0, Reward: -5411.535395378268, Done: False\n",
      "Action: 0, Reward: -5470.944580294419, Done: False\n",
      "Action: 1, Reward: -5149.437113443297, Done: False\n",
      "Action: 1, Reward: -5149.437113443297, Done: False\n",
      "Action: 0, Reward: -5149.437113443297, Done: False\n",
      "Action: 1, Reward: -5076.546479887177, Done: False\n",
      "Action: 0, Reward: -5076.546479887177, Done: False\n",
      "Action: 0, Reward: -5060.025082434037, Done: False\n",
      "Action: 0, Reward: -5046.807696370387, Done: False\n",
      "Action: 1, Reward: -4841.938882636661, Done: False\n",
      "Action: 0, Reward: -4841.938882636661, Done: False\n",
      "Action: 0, Reward: -5093.961539353178, Done: False\n",
      "Action: 0, Reward: -5070.439670104327, Done: False\n",
      "Action: 1, Reward: -5117.48374940484, Done: False\n",
      "Action: 1, Reward: -5117.48374940484, Done: False\n",
      "Action: 1, Reward: -5117.48374940484, Done: False\n",
      "Action: 0, Reward: -5117.48374940484, Done: False\n",
      "Action: 1, Reward: -5052.685621689273, Done: False\n",
      "Action: 1, Reward: -5052.685621689273, Done: False\n",
      "Action: 1, Reward: -5052.685621689273, Done: False\n",
      "Action: 1, Reward: -5052.685621689273, Done: False\n",
      "Action: 0, Reward: -5052.685621689273, Done: False\n",
      "Action: 0, Reward: -5062.3732921448845, Done: False\n",
      "Action: 1, Reward: -5194.775276087708, Done: False\n",
      "Action: 0, Reward: -5194.775276087708, Done: False\n",
      "Action: 1, Reward: -5240.2303132551015, Done: False\n",
      "Action: 1, Reward: -5240.2303132551015, Done: False\n",
      "Action: 0, Reward: -5240.2303132551015, Done: False\n",
      "Action: 0, Reward: -5169.2852370665705, Done: False\n",
      "Action: 0, Reward: -5266.028314650438, Done: False\n",
      "Action: 0, Reward: -5220.881893973078, Done: False\n",
      "Action: 0, Reward: -5188.63398340651, Done: False\n",
      "Action: 0, Reward: -5204.757938689794, Done: False\n",
      "Action: 0, Reward: -5072.542159482701, Done: False\n",
      "Action: 1, Reward: -5075.766623481443, Done: False\n",
      "Action: 0, Reward: -5075.766623481443, Done: False\n",
      "Action: 0, Reward: -5063.099726556678, Done: False\n",
      "Action: 0, Reward: -4926.931226953027, Done: False\n",
      "Action: 1, Reward: -5085.26647500623, Done: False\n",
      "Action: 0, Reward: -5085.26647500623, Done: False\n",
      "Action: 1, Reward: -5094.191576981829, Done: False\n",
      "Action: 0, Reward: -5094.191576981829, Done: False\n",
      "Action: 0, Reward: -5123.745074918629, Done: False\n",
      "Action: 1, Reward: -5091.236556889144, Done: False\n",
      "Action: 0, Reward: -5091.236556889144, Done: False\n",
      "Action: 0, Reward: -5018.146273504834, Done: False\n",
      "Action: 1, Reward: -5129.243844035873, Done: False\n",
      "Action: 0, Reward: -5129.243844035873, Done: False\n",
      "Action: 1, Reward: -5177.469220638436, Done: False\n",
      "Action: 1, Reward: -5177.469220638436, Done: False\n",
      "Action: 0, Reward: -5177.469220638436, Done: False\n",
      "Action: 1, Reward: -5141.613531754483, Done: False\n",
      "Action: 1, Reward: -5141.613531754483, Done: False\n",
      "Action: 0, Reward: -5141.613531754483, Done: False\n",
      "Action: 0, Reward: -5028.116847361596, Done: False\n",
      "Action: 0, Reward: -4830.413533773985, Done: False\n",
      "Action: 0, Reward: -4863.364086038587, Done: False\n",
      "Action: 1, Reward: -4614.403935687523, Done: False\n",
      "Action: 0, Reward: -4614.403935687523, Done: False\n",
      "Action: 0, Reward: -4546.06664912971, Done: False\n",
      "Action: 1, Reward: -4474.475495507596, Done: False\n",
      "Action: 0, Reward: -4474.475495507596, Done: False\n",
      "Action: 0, Reward: -4688.928802099401, Done: False\n",
      "Action: 1, Reward: -4863.172309293418, Done: False\n",
      "Action: 1, Reward: -4863.172309293418, Done: False\n",
      "Action: 0, Reward: -4863.172309293418, Done: False\n",
      "Action: 1, Reward: -4836.522236184977, Done: False\n",
      "Action: 1, Reward: -4836.522236184977, Done: False\n",
      "Action: 1, Reward: -4836.522236184977, Done: False\n",
      "Action: 1, Reward: -4836.522236184977, Done: False\n",
      "Action: 0, Reward: -4836.522236184977, Done: False\n",
      "Action: 0, Reward: -4880.538285037708, Done: False\n",
      "Action: 1, Reward: -4968.571788142369, Done: False\n",
      "Action: 1, Reward: -4968.571788142369, Done: False\n",
      "Action: 0, Reward: -4968.571788142369, Done: False\n",
      "Action: 0, Reward: -4930.715546716135, Done: False\n",
      "Action: 0, Reward: -5040.842729571086, Done: False\n",
      "Action: 0, Reward: -4941.040170987385, Done: False\n",
      "Action: 0, Reward: -4896.300489596143, Done: False\n",
      "Action: 0, Reward: -4903.183572443643, Done: False\n",
      "Action: 1, Reward: -5006.427672451095, Done: False\n",
      "Action: 0, Reward: -5006.427672451095, Done: False\n",
      "Action: 0, Reward: -4969.262984701286, Done: False\n",
      "Action: 0, Reward: -4905.069624366375, Done: False\n",
      "Action: 1, Reward: -4959.127320130304, Done: False\n",
      "Action: 0, Reward: -4959.127320130304, Done: False\n",
      "Action: 0, Reward: -4959.127320130304, Done: False\n",
      "Action: 0, Reward: -4737.8548537692295, Done: False\n",
      "Action: 0, Reward: -4717.110089163033, Done: False\n",
      "Action: 1, Reward: -4782.8004086716965, Done: False\n",
      "Action: 1, Reward: -4782.8004086716965, Done: False\n",
      "Action: 0, Reward: -4782.8004086716965, Done: False\n",
      "Action: 0, Reward: -4568.63530397862, Done: False\n",
      "Action: 1, Reward: -4680.984318863568, Done: False\n",
      "Action: 0, Reward: -4680.984318863568, Done: False\n",
      "Action: 0, Reward: -4891.854271866136, Done: False\n",
      "Action: 1, Reward: -4851.861967769259, Done: False\n",
      "Action: 1, Reward: -4851.861967769259, Done: False\n",
      "Action: 1, Reward: -4851.861967769259, Done: False\n",
      "Action: 0, Reward: -4851.861967769259, Done: False\n",
      "Action: 0, Reward: -4721.395656988919, Done: False\n",
      "Action: 0, Reward: -4672.030015993607, Done: False\n",
      "Action: 1, Reward: -4527.458922727353, Done: False\n",
      "Action: 0, Reward: -4527.458922727353, Done: False\n",
      "Action: 0, Reward: -4464.029369658818, Done: False\n",
      "Action: 1, Reward: -4449.934035310093, Done: False\n",
      "Action: 1, Reward: -4449.934035310093, Done: False\n",
      "Action: 0, Reward: -4449.934035310093, Done: False\n",
      "Action: 1, Reward: -4891.235570961463, Done: False\n",
      "Action: 0, Reward: -4891.235570961463, Done: False\n",
      "Action: 0, Reward: -4615.2930955936645, Done: False\n",
      "Action: 0, Reward: -4523.312403036928, Done: False\n",
      "Action: 0, Reward: -4576.968171584486, Done: False\n",
      "Action: 0, Reward: -4591.896943855662, Done: False\n",
      "Action: 1, Reward: -4618.022891876613, Done: False\n",
      "Action: 0, Reward: -4618.022891876613, Done: False\n",
      "Action: 0, Reward: -4750.729298339323, Done: False\n",
      "Action: 1, Reward: -4942.415762526739, Done: False\n",
      "Action: 0, Reward: -4942.415762526739, Done: False\n",
      "Action: 1, Reward: -4858.122249611578, Done: False\n",
      "Action: 1, Reward: -4858.122249611578, Done: False\n",
      "Action: 1, Reward: -4858.122249611578, Done: False\n",
      "Action: 1, Reward: -4858.122249611578, Done: False\n",
      "Action: 1, Reward: -4858.122249611578, Done: False\n",
      "Action: 0, Reward: -4858.122249611578, Done: False\n",
      "Action: 0, Reward: -4813.481049493457, Done: False\n",
      "Action: 1, Reward: -4943.346673426664, Done: False\n",
      "Action: 1, Reward: -4943.346673426664, Done: False\n",
      "Action: 0, Reward: -4943.346673426664, Done: False\n",
      "Action: 1, Reward: -4958.274031919516, Done: False\n",
      "Action: 0, Reward: -4958.274031919516, Done: False\n",
      "Action: 0, Reward: -5167.396064430897, Done: False\n",
      "Action: 1, Reward: -5045.725306784897, Done: False\n",
      "Action: 0, Reward: -5045.725306784897, Done: False\n",
      "Action: 0, Reward: -5099.367971387377, Done: False\n",
      "Action: 1, Reward: -5061.051724059914, Done: False\n",
      "Action: 1, Reward: -5061.051724059914, Done: False\n",
      "Action: 1, Reward: -5061.051724059914, Done: False\n",
      "Action: 0, Reward: -5061.051724059914, Done: False\n",
      "Action: 0, Reward: -4914.168418137646, Done: False\n",
      "Action: 1, Reward: -4987.60987545836, Done: False\n",
      "Action: 0, Reward: -4987.60987545836, Done: False\n",
      "Action: 0, Reward: -5056.322057865843, Done: False\n",
      "Action: 1, Reward: -5132.267689748794, Done: False\n",
      "Action: 0, Reward: -5132.267689748794, Done: False\n",
      "Action: 0, Reward: -5208.4961036871855, Done: False\n",
      "Action: 0, Reward: -5324.653926272329, Done: False\n",
      "Action: 0, Reward: -5092.338281102041, Done: False\n",
      "Action: 0, Reward: -5041.519596335908, Done: False\n",
      "Action: 1, Reward: -4939.881066436066, Done: False\n",
      "Action: 1, Reward: -4939.881066436066, Done: False\n",
      "Action: 0, Reward: -4939.881066436066, Done: False\n",
      "Action: 1, Reward: -4932.444999240796, Done: False\n",
      "Action: 0, Reward: -4932.444999240796, Done: False\n",
      "Action: 1, Reward: -4991.029328333694, Done: False\n",
      "Action: 1, Reward: -4991.029328333694, Done: False\n",
      "Action: 0, Reward: -4991.029328333694, Done: False\n",
      "Action: 1, Reward: -4942.543390908057, Done: False\n",
      "Action: 1, Reward: -4942.543390908057, Done: False\n",
      "Action: 1, Reward: -4942.543390908057, Done: False\n",
      "Action: 1, Reward: -4942.543390908057, Done: False\n",
      "Action: 1, Reward: -4942.543390908057, Done: False\n",
      "Action: 0, Reward: -4942.543390908057, Done: False\n",
      "Action: 0, Reward: -5039.045806916959, Done: False\n",
      "Action: 0, Reward: -4981.8591336008085, Done: False\n",
      "Action: 1, Reward: -5174.86434646702, Done: False\n",
      "Action: 0, Reward: -5174.86434646702, Done: False\n",
      "Action: 0, Reward: -5108.575283503421, Done: False\n",
      "Action: 1, Reward: -4951.5754386457875, Done: False\n",
      "Action: 0, Reward: -4951.5754386457875, Done: False\n",
      "Action: 1, Reward: -4743.639702963154, Done: False\n",
      "Action: 1, Reward: -4743.639702963154, Done: False\n",
      "Action: 1, Reward: -4743.639702963154, Done: False\n",
      "Action: 0, Reward: -4743.639702963154, Done: False\n",
      "Action: 0, Reward: -4763.843659853918, Done: False\n",
      "Action: 0, Reward: -4662.824234205211, Done: False\n",
      "Action: 1, Reward: -4733.537545115219, Done: False\n",
      "Action: 1, Reward: -4733.537545115219, Done: False\n",
      "Action: 1, Reward: -4733.537545115219, Done: False\n",
      "Action: 1, Reward: -4733.537545115219, Done: False\n",
      "Action: 0, Reward: -4733.537545115219, Done: False\n",
      "Action: 1, Reward: -4845.941926129216, Done: False\n",
      "Action: 1, Reward: -4845.941926129216, Done: False\n",
      "Action: 0, Reward: -4845.941926129216, Done: False\n",
      "Action: 0, Reward: -4677.1190642763795, Done: False\n",
      "Action: 1, Reward: -4713.531774638578, Done: False\n",
      "Action: 1, Reward: -4713.531774638578, Done: False\n",
      "Action: 0, Reward: -4713.531774638578, Done: False\n",
      "Action: 1, Reward: -4656.253225680489, Done: False\n",
      "Action: 0, Reward: -4656.253225680489, Done: False\n",
      "Action: 0, Reward: -4652.995008103034, Done: False\n",
      "Action: 1, Reward: -4714.904343030726, Done: False\n",
      "Action: 0, Reward: -4714.904343030726, Done: False\n",
      "Action: 1, Reward: -4640.275331453901, Done: False\n",
      "Action: 1, Reward: -4640.275331453901, Done: False\n",
      "Action: 0, Reward: -4640.275331453901, Done: False\n",
      "Action: 1, Reward: -4423.58421899557, Done: False\n",
      "Action: 0, Reward: -4423.58421899557, Done: False\n",
      "Action: 1, Reward: -4592.880375918909, Done: False\n",
      "Action: 1, Reward: -4592.880375918909, Done: False\n",
      "Action: 1, Reward: -4592.880375918909, Done: False\n",
      "Action: 1, Reward: -4592.880375918909, Done: False\n",
      "Action: 0, Reward: -4592.880375918909, Done: False\n",
      "Action: 1, Reward: -4567.539694938709, Done: False\n",
      "Action: 0, Reward: -4567.539694938709, Done: False\n",
      "Action: 1, Reward: -4637.594117472286, Done: False\n",
      "Action: 0, Reward: -4637.594117472286, Done: False\n",
      "Action: 0, Reward: -4504.955237915434, Done: False\n",
      "Action: 1, Reward: -4457.583101497315, Done: False\n",
      "Action: 0, Reward: -4457.583101497315, Done: False\n",
      "Action: 1, Reward: -4540.123071686881, Done: False\n",
      "Action: 0, Reward: -4540.123071686881, Done: False\n",
      "Action: 1, Reward: -4646.201110644925, Done: False\n",
      "Action: 1, Reward: -4646.201110644925, Done: False\n",
      "Action: 1, Reward: -4646.201110644925, Done: False\n",
      "Action: 1, Reward: -4646.201110644925, Done: False\n",
      "Action: 0, Reward: -4646.201110644925, Done: False\n",
      "Action: 0, Reward: -4733.833381325999, Done: False\n",
      "Action: 0, Reward: -4884.452224627475, Done: False\n",
      "Action: 1, Reward: -4983.038603872906, Done: False\n",
      "Action: 0, Reward: -4983.038603872906, Done: False\n",
      "Action: 1, Reward: -4966.499102255152, Done: False\n",
      "Action: 1, Reward: -4966.499102255152, Done: False\n",
      "Action: 1, Reward: -4966.499102255152, Done: False\n",
      "Action: 0, Reward: -4966.499102255152, Done: False\n",
      "Action: 0, Reward: -4894.788056579325, Done: False\n",
      "Action: 1, Reward: -4955.466425268565, Done: False\n",
      "Action: 1, Reward: -4955.466425268565, Done: False\n",
      "Action: 1, Reward: -4955.466425268565, Done: False\n",
      "Action: 0, Reward: -4955.466425268565, Done: False\n",
      "Action: 0, Reward: -4881.403573869111, Done: False\n",
      "Action: 1, Reward: -4969.181457615218, Done: False\n",
      "Action: 0, Reward: -4969.181457615218, Done: False\n",
      "Action: 1, Reward: -4889.804620047967, Done: False\n",
      "Action: 1, Reward: -4889.804620047967, Done: False\n",
      "Action: 1, Reward: -4889.804620047967, Done: False\n",
      "Action: 1, Reward: -4889.804620047967, Done: False\n",
      "Action: 0, Reward: -4889.804620047967, Done: False\n",
      "Action: 0, Reward: -4785.570766718331, Done: False\n",
      "Action: 1, Reward: -4714.252362809744, Done: False\n",
      "Action: 0, Reward: -4714.252362809744, Done: False\n",
      "Action: 0, Reward: -4885.902882273467, Done: False\n",
      "Action: 0, Reward: -4891.351831317451, Done: False\n",
      "Action: 0, Reward: -4785.092269172526, Done: False\n",
      "Action: 1, Reward: -4918.671521148171, Done: False\n",
      "Action: 0, Reward: -4918.671521148171, Done: False\n",
      "Action: 1, Reward: -5128.412781649866, Done: False\n",
      "Action: 0, Reward: -5128.412781649866, Done: False\n",
      "Action: 1, Reward: -5307.907580992986, Done: False\n",
      "Action: 0, Reward: -5307.907580992986, Done: False\n",
      "Action: 1, Reward: -5345.01003177261, Done: False\n",
      "Action: 0, Reward: -5345.01003177261, Done: False\n",
      "Action: 1, Reward: -5396.796377579934, Done: False\n",
      "Action: 0, Reward: -5396.796377579934, Done: False\n",
      "Action: 0, Reward: -5393.953491648339, Done: False\n",
      "Action: 1, Reward: -5328.558569472331, Done: False\n",
      "Action: 1, Reward: -5328.558569472331, Done: False\n",
      "Action: 1, Reward: -5328.558569472331, Done: False\n",
      "Action: 0, Reward: -5328.558569472331, Done: False\n",
      "Action: 1, Reward: -5131.981635453128, Done: False\n",
      "Action: 0, Reward: -5131.981635453128, Done: False\n",
      "Action: 0, Reward: -5021.711506291851, Done: False\n",
      "Action: 1, Reward: -4997.505597996184, Done: False\n",
      "Action: 0, Reward: -4997.505597996184, Done: False\n",
      "Action: 0, Reward: -4976.092777634433, Done: False\n",
      "Action: 0, Reward: -4823.529188638944, Done: False\n",
      "Action: 1, Reward: -4778.026721904114, Done: False\n",
      "Action: 1, Reward: -4778.026721904114, Done: False\n",
      "Action: 0, Reward: -4778.026721904114, Done: False\n",
      "Action: 1, Reward: -4694.307611047192, Done: False\n",
      "Action: 0, Reward: -4694.307611047192, Done: False\n",
      "Action: 1, Reward: -4715.393056446525, Done: False\n",
      "Action: 1, Reward: -4715.393056446525, Done: False\n",
      "Action: 1, Reward: -4715.393056446525, Done: False\n",
      "Action: 1, Reward: -4715.393056446525, Done: False\n",
      "Action: 1, Reward: -4715.393056446525, Done: False\n",
      "Action: 1, Reward: -4715.393056446525, Done: False\n",
      "Action: 0, Reward: -4715.393056446525, Done: False\n",
      "Action: 1, Reward: -4542.746162723417, Done: False\n",
      "Action: 0, Reward: -4542.746162723417, Done: False\n",
      "Action: 1, Reward: -4577.954104169069, Done: False\n",
      "Action: 0, Reward: -4577.954104169069, Done: False\n",
      "Action: 0, Reward: -4649.296201816356, Done: False\n",
      "Action: 1, Reward: -4659.866534464116, Done: False\n",
      "Action: 1, Reward: -4659.866534464116, Done: False\n",
      "Action: 1, Reward: -4659.866534464116, Done: False\n",
      "Action: 0, Reward: -4659.866534464116, Done: False\n",
      "Action: 1, Reward: -4644.45566462222, Done: False\n",
      "Action: 1, Reward: -4644.45566462222, Done: False\n",
      "Action: 1, Reward: -4644.45566462222, Done: False\n",
      "Action: 1, Reward: -4644.45566462222, Done: False\n",
      "Action: 0, Reward: -4644.45566462222, Done: False\n",
      "Action: 0, Reward: -4587.91127511562, Done: False\n",
      "Action: 0, Reward: -4563.678050966528, Done: False\n",
      "Action: 0, Reward: -4569.063744756243, Done: False\n",
      "Action: 1, Reward: -4536.751979922578, Done: False\n",
      "Action: 0, Reward: -4536.751979922578, Done: False\n",
      "Action: 0, Reward: -4553.075614112387, Done: False\n",
      "Action: 0, Reward: -4686.391754616245, Done: False\n",
      "Action: 0, Reward: -4776.176588625508, Done: False\n",
      "Action: 1, Reward: -4789.780424777901, Done: False\n",
      "Action: 0, Reward: -4789.780424777901, Done: False\n",
      "Action: 1, Reward: -4759.376038764769, Done: False\n",
      "Action: 1, Reward: -4759.376038764769, Done: False\n",
      "Action: 0, Reward: -4759.376038764769, Done: False\n",
      "Action: 0, Reward: -4807.094188716915, Done: False\n",
      "Action: 0, Reward: -4725.692113823096, Done: False\n",
      "Action: 0, Reward: -4736.9192388433985, Done: False\n",
      "Action: 0, Reward: -4624.640976468269, Done: False\n",
      "Action: 0, Reward: -4554.466345329849, Done: False\n",
      "Action: 1, Reward: -3886.4065087680774, Done: False\n",
      "Action: 1, Reward: -3886.4065087680774, Done: False\n",
      "Action: 1, Reward: -3886.4065087680774, Done: False\n",
      "Action: 0, Reward: -3886.4065087680774, Done: False\n",
      "Action: 0, Reward: -3816.4698137435853, Done: False\n",
      "Action: 1, Reward: -3851.438161255831, Done: False\n",
      "Action: 0, Reward: -3851.438161255831, Done: False\n",
      "Action: 0, Reward: -3983.6652835340756, Done: False\n",
      "Action: 0, Reward: -3719.210386171778, Done: False\n",
      "Action: 0, Reward: -3745.0804275871405, Done: False\n",
      "Action: 0, Reward: -3828.4417710128537, Done: False\n",
      "Action: 0, Reward: -3653.096825032655, Done: False\n",
      "Action: 1, Reward: -3693.3390391447965, Done: False\n",
      "Action: 0, Reward: -3693.3390391447956, Done: False\n",
      "Action: 0, Reward: -3761.6105591475307, Done: False\n",
      "Action: 1, Reward: -3838.4181187592294, Done: False\n",
      "Action: 1, Reward: -3838.4181187592294, Done: False\n",
      "Action: 1, Reward: -3838.4181187592294, Done: False\n",
      "Action: 0, Reward: -3838.4181187592294, Done: False\n",
      "Action: 1, Reward: -3892.3924501409138, Done: False\n",
      "Action: 0, Reward: -3892.3924501409138, Done: False\n",
      "Action: 0, Reward: -4078.154319500318, Done: False\n",
      "Action: 0, Reward: -4016.233057186695, Done: False\n",
      "Action: 0, Reward: -4145.704322610582, Done: False\n",
      "Action: 0, Reward: -4151.3324242134, Done: False\n",
      "Action: 1, Reward: -4061.266818722752, Done: False\n",
      "Action: 1, Reward: -4061.266818722752, Done: False\n",
      "Action: 1, Reward: -4061.266818722752, Done: False\n",
      "Action: 1, Reward: -4061.266818722752, Done: False\n",
      "Action: 0, Reward: -4061.266818722752, Done: False\n",
      "Action: 1, Reward: -4021.713757489152, Done: False\n",
      "Action: 1, Reward: -4021.713757489152, Done: False\n",
      "Action: 0, Reward: -4021.713757489152, Done: False\n",
      "Action: 0, Reward: -4041.6793191045717, Done: False\n",
      "Action: 1, Reward: -4035.9745953221045, Done: False\n",
      "Action: 0, Reward: -4035.9745953221045, Done: False\n",
      "Action: 0, Reward: -3925.844681452175, Done: False\n",
      "Action: 0, Reward: -3900.429000653121, Done: False\n",
      "Action: 0, Reward: -3897.6059624537975, Done: False\n",
      "Action: 1, Reward: -3897.6059624537975, Done: False\n",
      "Action: 1, Reward: -3897.6059624537975, Done: False\n",
      "Action: 1, Reward: -3897.6059624537975, Done: False\n",
      "Action: 1, Reward: -3897.6059624537975, Done: False\n",
      "Action: 0, Reward: -3897.6059624537975, Done: False\n",
      "Action: 0, Reward: -3930.1124194785543, Done: False\n",
      "Action: 0, Reward: -3953.7540282326026, Done: False\n",
      "Action: 0, Reward: -3900.5622541210296, Done: False\n",
      "Action: 1, Reward: -3853.279707734764, Done: False\n",
      "Action: 1, Reward: -3853.279707734764, Done: False\n",
      "Action: 1, Reward: -3853.279707734764, Done: False\n",
      "Action: 1, Reward: -3853.279707734764, Done: False\n",
      "Action: 0, Reward: -3853.279707734764, Done: False\n",
      "Action: 1, Reward: -3928.7858521024327, Done: False\n",
      "Action: 0, Reward: -3928.785852102432, Done: False\n",
      "Action: 1, Reward: -4105.321782064902, Done: False\n",
      "Action: 0, Reward: -4105.3217820649015, Done: False\n",
      "Action: 1, Reward: -4142.765728145364, Done: False\n",
      "Action: 1, Reward: -4142.765728145364, Done: False\n",
      "Action: 0, Reward: -4142.765728145364, Done: False\n",
      "Action: 0, Reward: -4114.3459677030705, Done: False\n",
      "Action: 1, Reward: -4279.702509320233, Done: False\n",
      "Action: 1, Reward: -4279.702509320233, Done: False\n",
      "Action: 1, Reward: -4279.702509320233, Done: False\n",
      "Action: 1, Reward: -4279.702509320233, Done: False\n",
      "Action: 1, Reward: -4279.702509320233, Done: False\n",
      "Action: 1, Reward: -4279.702509320233, Done: False\n",
      "Action: 0, Reward: -4279.702509320233, Done: False\n",
      "Action: 0, Reward: -4239.268761209173, Done: False\n",
      "Action: 1, Reward: -4343.921849254885, Done: False\n",
      "Action: 0, Reward: -4343.921849254885, Done: False\n",
      "Action: 0, Reward: -4194.453484739841, Done: False\n",
      "Action: 1, Reward: -4220.550361543822, Done: False\n",
      "Action: 0, Reward: -4220.550361543823, Done: False\n",
      "Action: 0, Reward: -4143.587166659514, Done: False\n",
      "Action: 0, Reward: -3999.2811762514357, Done: False\n",
      "Action: 0, Reward: -4109.916324412086, Done: False\n",
      "Action: 0, Reward: -4136.372700410795, Done: False\n",
      "Action: 1, Reward: -4227.765383306998, Done: False\n",
      "Action: 0, Reward: -4227.765383306998, Done: False\n",
      "Action: 0, Reward: -4129.807414217144, Done: False\n",
      "Action: 1, Reward: -4259.601808108557, Done: False\n",
      "Action: 0, Reward: -4259.601808108557, Done: False\n",
      "Action: 1, Reward: -4282.280898508631, Done: False\n",
      "Action: 1, Reward: -4282.280898508631, Done: False\n",
      "Action: 0, Reward: -4282.280898508631, Done: False\n",
      "Action: 0, Reward: -4342.722239092805, Done: False\n",
      "Action: 0, Reward: -4386.239803285281, Done: False\n",
      "Action: 0, Reward: -4393.49245144496, Done: False\n",
      "Action: 0, Reward: -4393.49245144496, Done: False\n",
      "Action: 0, Reward: -4492.615512899864, Done: False\n",
      "Action: 1, Reward: -4478.109658169039, Done: False\n",
      "Action: 1, Reward: -4478.109658169039, Done: False\n",
      "Action: 0, Reward: -4478.109658169039, Done: False\n",
      "Action: 0, Reward: -4554.597894412805, Done: False\n",
      "Action: 0, Reward: -4544.7268452087, Done: False\n",
      "Action: 1, Reward: -4601.476402378889, Done: False\n",
      "Action: 1, Reward: -4601.476402378889, Done: False\n",
      "Action: 1, Reward: -4601.476402378889, Done: False\n",
      "Action: 0, Reward: -4601.476402378889, Done: False\n",
      "Action: 1, Reward: -4546.89626768954, Done: False\n",
      "Action: 0, Reward: -4546.89626768954, Done: False\n",
      "Action: 1, Reward: -4410.568846135025, Done: False\n",
      "Action: 0, Reward: -4410.568846135025, Done: False\n",
      "Action: 0, Reward: -4537.48864527725, Done: False\n",
      "Action: 1, Reward: -4594.72771866138, Done: False\n",
      "Action: 1, Reward: -4594.72771866138, Done: False\n",
      "Action: 0, Reward: -4594.72771866138, Done: False\n",
      "Action: 1, Reward: -3743.464363032461, Done: False\n",
      "Action: 1, Reward: -3743.464363032461, Done: False\n",
      "Action: 1, Reward: -3743.464363032461, Done: False\n",
      "Action: 1, Reward: -3743.464363032461, Done: False\n",
      "Action: 1, Reward: -3743.464363032461, Done: False\n",
      "Action: 0, Reward: -3743.464363032461, Done: False\n",
      "Action: 0, Reward: -3637.7281662992973, Done: False\n",
      "Action: 0, Reward: -3666.096356089168, Done: False\n",
      "Action: 0, Reward: -3761.516739140553, Done: False\n",
      "Action: 1, Reward: -3506.2012440216213, Done: False\n",
      "Action: 1, Reward: -3506.2012440216213, Done: False\n",
      "Action: 1, Reward: -3506.2012440216213, Done: False\n",
      "Action: 0, Reward: -3506.2012440216213, Done: False\n",
      "Action: 0, Reward: -3443.027182592452, Done: False\n",
      "Action: 1, Reward: -3345.6336320997243, Done: False\n",
      "Action: 0, Reward: -3345.6336320997243, Done: False\n",
      "Action: 0, Reward: -3478.8278972367516, Done: False\n",
      "Action: 0, Reward: -3489.4829386216834, Done: False\n",
      "Action: 1, Reward: -2935.3964200862456, Done: False\n",
      "Action: 1, Reward: -2935.3964200862456, Done: False\n",
      "Action: 1, Reward: -2935.3964200862456, Done: False\n",
      "Action: 0, Reward: -2935.3964200862456, Done: False\n",
      "Action: 0, Reward: -2946.15821801934, Done: False\n",
      "Action: 0, Reward: -3121.0241840946173, Done: False\n",
      "Action: 0, Reward: -3161.379033438365, Done: False\n",
      "Action: 1, Reward: -3064.5297926934954, Done: False\n",
      "Action: 0, Reward: -3064.5297926934954, Done: False\n",
      "Action: 1, Reward: -3164.2247747280717, Done: False\n",
      "Action: 1, Reward: -3164.2247747280717, Done: False\n",
      "Action: 0, Reward: -3164.2247747280717, Done: False\n",
      "Action: 1, Reward: -3325.761965553388, Done: False\n",
      "Action: 0, Reward: -3325.761965553388, Done: False\n"
     ]
    }
   ],
   "source": [
    "# Define and set up the RandomAgent\n",
    "class RandomAgent:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, _):\n",
    "        return self.action_space.sample()\n",
    "\n",
    "# Initialize the RandomAgent with the environment's action space\n",
    "agent = RandomAgent(env.action_space)\n",
    "\n",
    "# Test the agent\n",
    "obs = env.reset()\n",
    "for _ in range(1000):\n",
    "    action = agent.act(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Action: {action}, Reward: {reward}, Done: {done}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a9c18",
   "metadata": {},
   "source": [
    "To explain each step we see our agent making decisions to either sell or buy a stock. With the decisions our agent is making he goes through a roller coaster of making and losing money. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85930f1f",
   "metadata": {},
   "source": [
    "it's normal to get negative rewards in a trading environment, especially if the agent's actions result in losses. In a trading scenario, the goal of the agent is to maximize its cumulative reward over time. Since trading involves risk and uncertainty, there will be times when the agent's actions result in losses, leading to negative rewards.\n",
    "\n",
    "Negative rewards can indicate that the agent's current strategy is not performing well or that it's making suboptimal decisions. The agent's learning process involves exploring different actions and learning from the outcomes, both positive and negative. Over time, through learning, the agent should aim to improve its strategy to achieve better outcomes and maximize its cumulative reward.\n",
    "\n",
    "In reinforcement learning, it's common to have a mix of positive and negative rewards as the agent explores and learns to navigate the environment effectively. The ultimate goal is for the agent to learn a policy that results in a positive cumulative reward over the long term.\n",
    "\n",
    "As for our agent pertaining to our dataset, it seems to be learning over the many iterations. With some steps it seems like its learning how to make smarter investments. By the last iteration, its made back a lot of the money its lost over the course of its step cycle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
